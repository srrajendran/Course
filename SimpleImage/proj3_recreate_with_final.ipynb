{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from tensorflow import set_random_seed\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3896 samples, validate on 979 samples\n",
      "Epoch 1/20\n",
      "3896/3896 [==============================] - 3s 810us/step - loss: 2.2257 - acc: 0.2346 - val_loss: 2.0920 - val_acc: 0.4147\n",
      "Epoch 2/20\n",
      "3896/3896 [==============================] - 2s 505us/step - loss: 1.9429 - acc: 0.5118 - val_loss: 1.8046 - val_acc: 0.5832\n",
      "Epoch 3/20\n",
      "3896/3896 [==============================] - 2s 559us/step - loss: 1.6268 - acc: 0.6512 - val_loss: 1.4847 - val_acc: 0.6864\n",
      "Epoch 4/20\n",
      "3896/3896 [==============================] - 2s 529us/step - loss: 1.3086 - acc: 0.7279 - val_loss: 1.1920 - val_acc: 0.7314\n",
      "Epoch 5/20\n",
      "3896/3896 [==============================] - 2s 629us/step - loss: 1.0517 - acc: 0.7744 - val_loss: 0.9756 - val_acc: 0.7814\n",
      "Epoch 6/20\n",
      "3896/3896 [==============================] - 2s 514us/step - loss: 0.8723 - acc: 0.8113 - val_loss: 0.8287 - val_acc: 0.8059\n",
      "Epoch 7/20\n",
      "3896/3896 [==============================] - 2s 532us/step - loss: 0.7490 - acc: 0.8368 - val_loss: 0.7258 - val_acc: 0.8274\n",
      "Epoch 8/20\n",
      "3896/3896 [==============================] - 2s 507us/step - loss: 0.6613 - acc: 0.8509 - val_loss: 0.6500 - val_acc: 0.8458\n",
      "Epoch 9/20\n",
      "3896/3896 [==============================] - 2s 604us/step - loss: 0.5970 - acc: 0.8614 - val_loss: 0.5912 - val_acc: 0.8550\n",
      "Epoch 10/20\n",
      "3896/3896 [==============================] - 2s 522us/step - loss: 0.5475 - acc: 0.8719 - val_loss: 0.5503 - val_acc: 0.8662\n",
      "Epoch 11/20\n",
      "3896/3896 [==============================] - 2s 571us/step - loss: 0.5076 - acc: 0.8791 - val_loss: 0.5171 - val_acc: 0.8703\n",
      "Epoch 12/20\n",
      "3896/3896 [==============================] - 2s 597us/step - loss: 0.4759 - acc: 0.8855 - val_loss: 0.4867 - val_acc: 0.8815\n",
      "Epoch 13/20\n",
      "3896/3896 [==============================] - 2s 577us/step - loss: 0.4494 - acc: 0.8927 - val_loss: 0.4689 - val_acc: 0.8856\n",
      "Epoch 14/20\n",
      "3896/3896 [==============================] - 3s 777us/step - loss: 0.4276 - acc: 0.8971 - val_loss: 0.4439 - val_acc: 0.8866\n",
      "Epoch 15/20\n",
      "3896/3896 [==============================] - 3s 804us/step - loss: 0.4079 - acc: 0.9002 - val_loss: 0.4288 - val_acc: 0.8836\n",
      "Epoch 16/20\n",
      "3896/3896 [==============================] - 2s 641us/step - loss: 0.3920 - acc: 0.9002 - val_loss: 0.4181 - val_acc: 0.8887\n",
      "Epoch 17/20\n",
      "3896/3896 [==============================] - 2s 521us/step - loss: 0.3776 - acc: 0.9032 - val_loss: 0.4041 - val_acc: 0.8856\n",
      "Epoch 18/20\n",
      "3896/3896 [==============================] - 2s 513us/step - loss: 0.3646 - acc: 0.9058 - val_loss: 0.3904 - val_acc: 0.8917\n",
      "Epoch 19/20\n",
      "3896/3896 [==============================] - 2s 518us/step - loss: 0.3525 - acc: 0.9094 - val_loss: 0.3802 - val_acc: 0.8958\n",
      "Epoch 20/20\n",
      "3896/3896 [==============================] - 2s 493us/step - loss: 0.3417 - acc: 0.9125 - val_loss: 0.3725 - val_acc: 0.8948\n",
      "{'val_loss': [2.092044461857189, 1.8045935457890074, 1.4846863904939365, 1.1920175905490678, 0.9756249493183958, 0.8286509736687463, 0.7258009109360692, 0.6500310640900079, 0.5911874005816443, 0.5502603086314722, 0.5170817994973999, 0.48666405723457806, 0.4689272189469089, 0.4439261763283376, 0.4287815311347135, 0.41809456898194414, 0.40408697273806726, 0.3903870147570161, 0.3801560370866076, 0.37251128224357277], 'val_acc': [0.4147088886281443, 0.5832482124008124, 0.6864147132702088, 0.731358529050455, 0.7814096053481955, 0.8059244098653588, 0.82737487341459, 0.8457609761479683, 0.8549540338769509, 0.8661899853410224, 0.8702757930244196, 0.8815117471064684, 0.8855975407258483, 0.8866189994047319, 0.8835546486954888, 0.8886618935051198, 0.8855975450485549, 0.8917262565736508, 0.8958120593863926, 0.8947906033254863], 'loss': [2.225736978852039, 1.942892346783585, 1.6267871066040571, 1.3086309819740436, 1.0516881579246364, 0.8723282226546833, 0.7490261276644603, 0.6612655932898394, 0.5970098513352553, 0.5475498149037606, 0.5075653812846119, 0.47593992495683674, 0.44935748874529186, 0.4275584442414787, 0.40791272621379987, 0.39195728161251764, 0.37763251550878096, 0.3646249152429295, 0.35246529789675923, 0.34173452517579955], 'acc': [0.2345995891693926, 0.5118069823762474, 0.6511806931339006, 0.7279260782735304, 0.7743839876118137, 0.811344969566353, 0.8367556487755119, 0.8508726883473092, 0.8613962999849104, 0.8719199160286044, 0.8791067732433029, 0.8855236138406476, 0.8927104714225205, 0.8970739216040782, 0.9001540070441714, 0.9001540036172103, 0.9032340884453463, 0.9058008202537129, 0.9093942497789982, 0.9124743350967]}\n",
      "Train on 3898 samples, validate on 977 samples\n",
      "Epoch 1/20\n",
      "3898/3898 [==============================] - 4s 999us/step - loss: 2.1989 - acc: 0.2596 - val_loss: 2.0547 - val_acc: 0.3736\n",
      "Epoch 2/20\n",
      "3898/3898 [==============================] - 2s 551us/step - loss: 1.9339 - acc: 0.4497 - val_loss: 1.7744 - val_acc: 0.5322\n",
      "Epoch 3/20\n",
      "3898/3898 [==============================] - 2s 563us/step - loss: 1.6355 - acc: 0.5962 - val_loss: 1.4618 - val_acc: 0.6643\n",
      "Epoch 4/20\n",
      "3898/3898 [==============================] - 2s 563us/step - loss: 1.3319 - acc: 0.7170 - val_loss: 1.1740 - val_acc: 0.7615\n",
      "Epoch 5/20\n",
      "3898/3898 [==============================] - 2s 576us/step - loss: 1.0762 - acc: 0.7794 - val_loss: 0.9570 - val_acc: 0.8076\n",
      "Epoch 6/20\n",
      "3898/3898 [==============================] - 2s 548us/step - loss: 0.8891 - acc: 0.8173 - val_loss: 0.8093 - val_acc: 0.8321\n",
      "Epoch 7/20\n",
      "3898/3898 [==============================] - 2s 542us/step - loss: 0.7591 - acc: 0.8335 - val_loss: 0.7055 - val_acc: 0.8424\n",
      "Epoch 8/20\n",
      "3898/3898 [==============================] - 2s 513us/step - loss: 0.6668 - acc: 0.8466 - val_loss: 0.6362 - val_acc: 0.8485\n",
      "Epoch 9/20\n",
      "3898/3898 [==============================] - 2s 549us/step - loss: 0.6001 - acc: 0.8617 - val_loss: 0.5835 - val_acc: 0.8588\n",
      "Epoch 10/20\n",
      "3898/3898 [==============================] - 2s 605us/step - loss: 0.5501 - acc: 0.8674 - val_loss: 0.5416 - val_acc: 0.8628\n",
      "Epoch 11/20\n",
      "3898/3898 [==============================] - 2s 504us/step - loss: 0.5103 - acc: 0.8746 - val_loss: 0.5123 - val_acc: 0.8649\n",
      "Epoch 12/20\n",
      "3898/3898 [==============================] - 2s 499us/step - loss: 0.4779 - acc: 0.8828 - val_loss: 0.4901 - val_acc: 0.8700\n",
      "Epoch 13/20\n",
      "3898/3898 [==============================] - 3s 791us/step - loss: 0.4522 - acc: 0.8889 - val_loss: 0.4681 - val_acc: 0.8741\n",
      "Epoch 14/20\n",
      "3898/3898 [==============================] - 3s 701us/step - loss: 0.4289 - acc: 0.8899 - val_loss: 0.4524 - val_acc: 0.8751\n",
      "Epoch 15/20\n",
      "3898/3898 [==============================] - 2s 509us/step - loss: 0.4100 - acc: 0.8956 - val_loss: 0.4401 - val_acc: 0.8792\n",
      "Epoch 16/20\n",
      "3898/3898 [==============================] - 2s 539us/step - loss: 0.3938 - acc: 0.8999 - val_loss: 0.4307 - val_acc: 0.8772\n",
      "Epoch 17/20\n",
      "3898/3898 [==============================] - 3s 709us/step - loss: 0.3793 - acc: 0.9025 - val_loss: 0.4155 - val_acc: 0.8823\n",
      "Epoch 18/20\n",
      "3898/3898 [==============================] - 3s 764us/step - loss: 0.3663 - acc: 0.9041 - val_loss: 0.4059 - val_acc: 0.8813\n",
      "Epoch 19/20\n",
      "3898/3898 [==============================] - 2s 563us/step - loss: 0.3548 - acc: 0.9074 - val_loss: 0.3983 - val_acc: 0.8905\n",
      "Epoch 20/20\n",
      "3898/3898 [==============================] - 2s 631us/step - loss: 0.3447 - acc: 0.9084 - val_loss: 0.3929 - val_acc: 0.8833\n",
      "{'val_loss': [2.0547309119479316, 1.774393086911712, 1.4618490398723247, 1.1739540573518377, 0.9569622862668462, 0.8093004784296088, 0.7054938665431988, 0.6362004275819785, 0.58345819873966, 0.5415607142960891, 0.5122796856515117, 0.49013094459121764, 0.4681115351777482, 0.45237041117591037, 0.44010065753725924, 0.4306883858926709, 0.4154988704830744, 0.4058539894244566, 0.3982517912053525, 0.3928759390280459], 'val_acc': [0.3735926300210987, 0.5322415553864583, 0.664278395832378, 0.761514843669372, 0.8075742060232797, 0.8321392116429496, 0.8423746252621208, 0.8485158681259428, 0.8587512777796055, 0.8628454494500721, 0.8648925304046795, 0.8700102376718238, 0.8741043947004125, 0.8751279400583422, 0.8792221068481828, 0.8771750210129495, 0.8822927282800938, 0.8812691878027902, 0.8904810578942665, 0.8833162647918888], 'loss': [2.198918994479818, 1.933867690072664, 1.6354507218880063, 1.3319297794074876, 1.076174079699049, 0.8891239116105011, 0.7590597066712905, 0.6668076138425448, 0.6000705071753144, 0.5501471677763514, 0.5102683792302644, 0.47787019046163975, 0.45223147536376124, 0.4289360979907387, 0.4099756137660493, 0.3938284974761227, 0.37934885130838714, 0.36631665557332377, 0.3548485170027242, 0.3447239288019486], 'acc': [0.2596203172861337, 0.44971780501126385, 0.596203182708795, 0.7170343811601293, 0.7793740376012028, 0.8173422263242331, 0.8335043638103616, 0.8465879950968653, 0.8617239630852314, 0.8673678780592913, 0.8745510519131934, 0.8827603915338336, 0.8889173920977843, 0.8899435591489734, 0.8955874847962099, 0.8999486922177979, 0.9025141107785267, 0.9040533553764966, 0.9073884032089444, 0.9084145689756825]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3900 samples, validate on 975 samples\n",
      "Epoch 1/20\n",
      "3900/3900 [==============================] - 3s 884us/step - loss: 2.1924 - acc: 0.2564 - val_loss: 2.0702 - val_acc: 0.4226\n",
      "Epoch 2/20\n",
      "3900/3900 [==============================] - 2s 578us/step - loss: 1.9432 - acc: 0.4972 - val_loss: 1.7955 - val_acc: 0.5815\n",
      "Epoch 3/20\n",
      "3900/3900 [==============================] - 2s 604us/step - loss: 1.6452 - acc: 0.6292 - val_loss: 1.4827 - val_acc: 0.6821\n",
      "Epoch 4/20\n",
      "3900/3900 [==============================] - 2s 579us/step - loss: 1.3414 - acc: 0.7128 - val_loss: 1.2028 - val_acc: 0.7169\n",
      "Epoch 5/20\n",
      "1680/3900 [===========>..................] - ETA: 1s - loss: 1.1309 - acc: 0.7583"
     ]
    }
   ],
   "source": [
    "class NeuralNet:\n",
    "\n",
    "    def __init__(self, nClasses, randomSeed, epochs):\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.reshapedImages = None\n",
    "        self.categoricalLabels = None\n",
    "        self.nClasses = nClasses\n",
    "        self.testingDataIndexes = []\n",
    "        self.trainingValidationDataIndexes = []\n",
    "        self.dataSize = 0\n",
    "        self.trainingSetSize = 0\n",
    "        self.validationSetSize = 0\n",
    "        self.testingSetSize = 0\n",
    "        self.x_train = None\n",
    "        self.x_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.randomSeed = randomSeed\n",
    "        self.loss = np.zeros(epochs)\n",
    "        self.acc = np.zeros(epochs)\n",
    "        self.val_loss = np.zeros(epochs)\n",
    "        self.val_acc = np.zeros(epochs)\n",
    "        self.epochs = epochs\n",
    "        self.model=None\n",
    "\n",
    "\n",
    "    def loadData(self):\n",
    "        self.images = np.load('images.npy')\n",
    "        self.labels = np.load('labels.npy')\n",
    "\n",
    "    def normalize(self):\n",
    "        #self.reshapedImages = tf.keras.utils.normalize(self.reshapedImages, axis=1)\n",
    "        self.reshapedImages /= 225\n",
    "    def processData(self):\n",
    "        count = 0\n",
    "        self.dataSize = len(self.images)\n",
    "        self.reshapedImages = np.zeros((self.dataSize, len(self.images[0].reshape(-1))))\n",
    "        self.categoricalLabels = np.zeros((self.dataSize, self.nClasses))\n",
    "        while count < self.dataSize:\n",
    "            self.reshapedImages[count] = self.images[count].reshape(-1)\n",
    "            self.categoricalLabels[count] = to_categorical(self.labels[count], num_classes = self.nClasses, dtype = 'float32')\n",
    "            count += 1\n",
    "\n",
    "    def calculateDataSetSizes(self, training, validation):\n",
    "        self.trainingSetSize = int(self.dataSize * training)\n",
    "        self.validationSetSize = int(self.dataSize * validation)\n",
    "        self.testingSetSize = self.dataSize - (self.trainingSetSize + self.validationSetSize)\n",
    "\n",
    "    def getDataSets(self, testing):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.reshapedImages, self.labels, test_size=testing, random_state=1, stratify=self.categoricalLabels)\n",
    "\n",
    "\n",
    "\n",
    "    def runModel(self, x_train, y_train, x_val, y_val):\n",
    "        # Model Template\n",
    "        model = Sequential() # declare model\n",
    "        model.add(Dense(100, input_shape=(28*28, ), activation = 'relu')) # first layer\n",
    "        # Hidden Layer 1\n",
    "        model.add(Dense(100, activation = 'relu'))\n",
    "        # Hidden Layer 2\n",
    "        #\n",
    "        # Fill in Model Here\n",
    "        # Hidden Layer 3\n",
    "        #model.add(Dense(15, activation = 'relu'))\n",
    "\n",
    "        # Hidden Layer 4\n",
    "        #model.add(Dense(15, activation = 'relu'))\n",
    "\n",
    "        # Hidden Layer 5\n",
    "        #         model.add(Dense(75, activation = 'relu'))\n",
    "        #\n",
    "        model.add(Dense(10, activation = 'softmax')) # last layer\n",
    "\n",
    "\n",
    "        # Compile Model\n",
    "        model.compile(optimizer='sgd',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Train Model\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            validation_data = (x_val, y_val),\n",
    "                            epochs=self.epochs,\n",
    "                            batch_size=80)\n",
    "        self.model=model\n",
    "\n",
    "        #Save model\n",
    "        import os\n",
    "        save_dir = cwd\n",
    "        model_name = 'trained_model.proj3'\n",
    "        model_path = os.path.join(save_dir, model_name)\n",
    "        self.model.save(model_path)\n",
    "        \n",
    "        # Report Results\n",
    "        print(history.history)\n",
    "        return history\n",
    "\n",
    "    def predictModel(self):\n",
    "        y_pred=model.predict(X_test)\n",
    "\n",
    "    def performCrossVal(self):\n",
    "        kfold = StratifiedKFold(n_splits = 5, random_state = self.randomSeed)\n",
    "        histories = []\n",
    "        cat_y_train = to_categorical(self.y_train, num_classes = self.nClasses, dtype = 'float32')\n",
    "        for train, validate in kfold.split(self.x_train, self.y_train):\n",
    "            history = self.runModel(self.x_train[train], cat_y_train[train], self.x_train[validate], cat_y_train[validate])\n",
    "            histories.append(history)\n",
    "\n",
    "        for hist in histories:\n",
    "            n = 0\n",
    "            while n < self.epochs:\n",
    "                self.loss[n] += hist.history['loss'][n]\n",
    "                self.acc[n] += hist.history['acc'][n]\n",
    "                self.val_loss[n] += hist.history['val_loss'][n]\n",
    "                self.val_acc[n] += hist.history['val_acc'][n]\n",
    "                n += 1\n",
    "\n",
    "        self.loss = np.true_divide(self.loss, len(histories))\n",
    "        self.acc = np.true_divide(self.acc, len(histories))\n",
    "        self.val_loss = np.true_divide(self.val_loss, len(histories))\n",
    "        self.val_acc = np.true_divide(self.val_acc, len(histories))\n",
    "\n",
    "        print(\"self.loss = \" + str(self.loss))\n",
    "        print(\"self.acc = \" + str(self.acc))\n",
    "        print(\"self.val_loss = \" + str(self.val_loss))\n",
    "        print(\"self.val_acc = \" + str(self.val_acc))\n",
    "        \n",
    "    def predict(self):\n",
    "        # load the model and create predictions on the test set\n",
    "        mnist_model = load_model(\"trained_model.proj3\")\n",
    "        predicted_classes = mnist_model.predict_classes(self.x_test)\n",
    "\n",
    "        # see which we predicted correctly and which not\n",
    "        correct_indices = np.nonzero(predicted_classes == self.y_test)[0]\n",
    "        incorrect_indices = np.nonzero(predicted_classes != self.y_test)[0]\n",
    "        print()\n",
    "        print(len(correct_indices),\" classified correctly\")\n",
    "        print(len(incorrect_indices),\" classified incorrectly\")\n",
    "\n",
    "        # adapt figure size to accomodate 18 subplots\n",
    "        plt.rcParams['figure.figsize'] = (7,14)\n",
    "\n",
    "        figure_evaluation = plt.figure()\n",
    "\n",
    "        # plot 9 correct predictions\n",
    "        for i, correct in enumerate(correct_indices[:9]):\n",
    "            plt.subplot(6,3,i+1)\n",
    "            plt.imshow(self.x_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "            plt.title(\n",
    "              \"label:{}, Truth:{}\".format(predicted_classes[correct],\n",
    "                                                self.y_test[correct]))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "        # plot 9 incorrect predictions\n",
    "        for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "            plt.subplot(6,3,i+10)\n",
    "            plt.imshow(self.x_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "            plt.title(\n",
    "              \"label:{}, Truth:{}\".format(predicted_classes[incorrect], \n",
    "                                               self.y_test[incorrect]))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        figure_evaluation\n",
    "        \n",
    "    def plot_metrics(self):\n",
    "        # plotting the metrics\n",
    "        fig = plt.figure()\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(self.acc)\n",
    "        plt.plot(self.val_acc)\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        fig.show\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train = 0.6\n",
    "    validate = 0.15\n",
    "    test = 0.25\n",
    "    n_classes = 10\n",
    "    randomSeed = 1\n",
    "    epochs = 20\n",
    "    np.random.seed(randomSeed)\n",
    "    #main(train, validate, test, n_classes)\n",
    "\n",
    "    net = NeuralNet(n_classes, randomSeed, epochs)\n",
    "    net.loadData()\n",
    "    net.processData()\n",
    "    net.normalize()\n",
    "    net.calculateDataSetSizes(train, validate)\n",
    "    net.getDataSets(test)\n",
    "    net.performCrossVal()\n",
    "    net.predictModel\n",
    "    net.predict()\n",
    "    net.plot_metrics()\n",
    "\n",
    "#results = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01514964 0.09838519 0.04320014 ... 0.6064487  0.06891719 0.07318833]\n",
      " [0.0091253  0.66804224 0.03324823 ... 0.01958369 0.13850038 0.01751763]\n",
      " [0.01997857 0.04155824 0.29710037 ... 0.00939071 0.37953192 0.02422441]\n",
      " ...\n",
      " [0.0858889  0.01374451 0.46914336 ... 0.04438535 0.11808003 0.05197614]\n",
      " [0.01016338 0.01254855 0.12352161 ... 0.06587429 0.0487644  0.2672508 ]\n",
      " [0.04395359 0.02054369 0.10755294 ... 0.09835456 0.05627401 0.17508022]]\n",
      "[7 1 8 ... 2 8 3]\n",
      "[[145   0   6   4   0   2   4   1   1   0]\n",
      " [  0 155   5   0   0   0   1   1  20   0]\n",
      " [  3   3 108   5   2   2  10   0  23   3]\n",
      " [  4   7  29  82   0  16   2   3  17   7]\n",
      " [  2   4   6   0  48   3   8   7   7  79]\n",
      " [ 15  18   7   7   3  59   6   3  18   6]\n",
      " [  6  11   4   0   0   1 140   0   1   3]\n",
      " [  4  12   2   2   4   6   1 123   3  14]\n",
      " [  0   2  25   4   1  11   1   2  93  11]\n",
      " [  1   6   4   1   7   2   3  18   9 110]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=net.model.predict(net.x_test)\n",
    "print(y_pred)\n",
    "y_true=net.y_test\n",
    "print(net.y_test)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, classification_report\n",
    "matrix = confusion_matrix(y_true, y_pred.argmax(axis=1))\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       163\n",
      "           1       0.71      0.85      0.77       182\n",
      "           2       0.55      0.68      0.61       159\n",
      "           3       0.78      0.49      0.60       167\n",
      "           4       0.74      0.29      0.42       164\n",
      "           5       0.58      0.42      0.48       142\n",
      "           6       0.80      0.84      0.82       166\n",
      "           7       0.78      0.72      0.75       171\n",
      "           8       0.48      0.62      0.54       150\n",
      "           9       0.47      0.68      0.56       161\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      1625\n",
      "   macro avg       0.67      0.65      0.64      1625\n",
      "weighted avg       0.67      0.65      0.65      1625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_true, y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
